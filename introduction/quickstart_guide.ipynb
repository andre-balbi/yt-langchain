{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import find_dotenv, load_dotenv\n",
    "from langchain.llms import OpenAI\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "from langchain.agents.load_tools import get_all_tool_names\n",
    "from langchain import ConversationChain\n",
    "\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(find_dotenv(\"KEYS.env\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Python é a inteligência no horizonte\n",
      "Informando e preparando para o futuro\n",
      "A Inteligência Artificial está aqui\n",
      "Para nos ajudar a crescer ainda mais\n",
      "\n",
      "Aprendendo o que é real e o que é virtual\n",
      "Trazendo essas informações para nós\n",
      "Python trabalhando como um gênio\n",
      "Criando soluções para o próximo passo\n",
      "\n",
      "Não se trata de mágica ou de sorte\n",
      "Mas sim de estudo e dedicação\n",
      "Python e AI nos ajudando a ver\n",
      "Como podemos melhorar a vida de todos\n",
      "\n",
      "Python e AI, juntos, criando o futuro\n",
      "Com soluções inovadoras e eficazes\n",
      "Eles nos ajudarão a progredir\n",
      "Trazendo o melhor para todos nós.\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------\n",
    "# LLMs: Get predictions from a language modely\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "# Import the OpenAI module to use the language model\n",
    "llm = OpenAI(model_name=\"text-davinci-003\")\n",
    "\n",
    "# Define the instruction for the model to follow\n",
    "prompt = \"Escreva um poema sobre Python e AI\"\n",
    "\n",
    "# Generate text using the language model and the defined instruction\n",
    "output = llm(prompt)\n",
    "\n",
    "# Print the generated text to the output\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Até o momento, não há nada de novo, apenas um ponto de partida para interagir com este modelo de linguagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Olá!\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " Olá! Como você está?\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------\n",
    "# Memory: Persist application state between runs of a chain\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "# Create an instance of the OpenAI language model\n",
    "llm = OpenAI()\n",
    "\n",
    "# Create a ConversationChain to manage the conversation with the language model\n",
    "# Set verbose to True for detailed information about the conversation\n",
    "conversation = ConversationChain(llm=llm, verbose=True)\n",
    "\n",
    "# Use the conversation to predict a response based on the input message \"Olá!\"\n",
    "output = conversation.predict(input=\"Olá!\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Olá!\n",
      "AI:  Olá! Como você está?\n",
      "Human: Estou bem! Apenas conversando com uma IA.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " É muito legal conversar com você! Eu sempre me sinto honrado quando alguém me procura para conversar. Você gostaria de falar sobre algum assunto específico?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Use the conversation to predict a response based on the input message \"Estou bem! Apenas conversando com uma IA.\"\n",
    "output = conversation.predict(\n",
    "    input=\"Estou bem! Apenas conversando com uma IA.\"\n",
    ")\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Qual é um bom nome para uma empresa que faz Smart Apps que utilizam Large Language Models (LLMs)?'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --------------------------------------------------------------\n",
    "# Prompt Templates: Manage prompts for LLMs\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "# Define a template for prompts that can be customized with variables\n",
    "# The template has an input variable called \"product\"\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"product\"],\n",
    "    template=\"Qual é um bom nome para uma empresa que faz {product}?\",\n",
    ")\n",
    "\n",
    "# Format the template by replacing the \"product\" variable with the provided value\n",
    "# In this case, the product is \"Smart Apps using Large Language Models (LLMs)\"\n",
    "formatted_prompt = prompt.format(product=\"Smart Apps que utilizam Large Language Models (LLMs)\")\n",
    "\n",
    "formatted_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "SmileTech AI Solutions.\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------\n",
    "# Chains: Combine LLMs and prompts in multi-step workflows\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "# Import the OpenAI module to use the language model\n",
    "llm = OpenAI()\n",
    "\n",
    "# Define a template for prompts that can be customized with variables\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"product\"],\n",
    "    template=\"Qual é um bom nome para uma empresa que faz {product}?\",\n",
    ")\n",
    "\n",
    "# Create a chain to combine the language model and the prompt\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# Run the chain with the input message \"AI Chatbots for Dental Offices\"\n",
    "output = chain.run(\"Chatbots com AI para consultórios odontológicos\")\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Agora, podemos começar a imaginar como poderíamos transformar isso em uma aplicação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m Python is a programming language, so I should look for the history of its creation.\n",
      "Action: Wikipedia\n",
      "Action Input: History of Python\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mPage: History of Python\n",
      "Summary: The programming language Python was conceived in the late 1980s, and its implementation was started in December 1989 by Guido van Rossum at CWI in the Netherlands as a successor to ABC capable of exception handling and interfacing with the Amoeba operating system. Van Rossum is Python's principal author, and his continuing central role in deciding the direction of Python is reflected in the title given to him by the Python community, Benevolent Dictator for Life (BDFL). (However, Van rossum stepped down as leader on July 12, 2018.). Python was named after the BBC TV show Monty Python's Flying Circus.Python 2.0 was released on October 16, 2000, with many major new features, including a cycle-detecting garbage collector (in addition to reference counting) for memory management and support for Unicode. However, the most important change was to the development process itself, with a shift to a more transparent and community-backed process.Python 3.0, a major, backwards-incompatible release, was released on December 3, 2008 after a long period of testing. Many of its major features have also been backported to the backwards-compatible, though now-unsupported, Python 2.6 and 2.7.\n",
      "\n",
      "Page: Python (programming language)\n",
      "Summary: Python is a high-level, general-purpose programming language. Its design philosophy emphasizes code readability with the use of significant indentation.Python is dynamically typed and garbage-collected. It supports multiple programming paradigms, including structured (particularly procedural), object-oriented and functional programming. It is often described as a \"batteries included\" language due to its comprehensive standard library.Guido van Rossum began working on Python in the late 1980s as a successor to the ABC programming language and first released it in 1991 as Python 0.9.0. Python 2.0 was released in 2000. Python 3.0, released in 2008, was a major revision not completely backward-compatible with earlier versions. Python 2.7.18, released in 2020, was the last release of Python 2.Python consistently ranks as one of the most popular programming languages.\n",
      "\n",
      "Page: Colt Python\n",
      "Summary: The Colt Python is a .357 Magnum caliber revolver manufactured by Colt's Manufacturing Company of Hartford, Connecticut. It was first introduced in 1955, the same year as Smith & Wesson's M29 .44 Magnum. The Colt Python is intended for the premium revolver market segment. Some firearm collectors and writers such as Jeff Cooper, Ian V. Hogg, Chuck Hawks, Leroy Thompson, Scott Wolber, Renee Smeets and Martin Dougherty have described the Python as \"the finest production revolver ever made\".\n",
      "\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: A linguagem Python foi recriada em 1989 por Guido van Rossum e multiplicar o ano por 3 resulta em 5.667.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "A linguagem Python foi recriada em 1989 por Guido van Rossum e multiplicar o ano por 3 resulta em 5.667.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --------------------------------------------------------------\n",
    "# Agents: Dynamically Call Chains Based on User Input\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "# Let chains choose which tools to use given high-level directives\n",
    "\n",
    "# Create an instance of the OpenAI language model\n",
    "llm = OpenAI()\n",
    "\n",
    "# Get the names of all available tools\n",
    "get_all_tool_names()\n",
    "\n",
    "# Load specific tools to be used, such as \"wikipedia\" and \"llm-math\", using the language model instance\n",
    "tools = load_tools([\"wikipedia\", \n",
    "                    \"llm-math\"], \n",
    "                     llm=llm)\n",
    "\n",
    "# Finally, initialize an agent with the loaded tools, the language model, and the desired agent type.\n",
    "# In this case, the agent is configured as \"ZERO_SHOT_REACT_DESCRIPTION\" with verbose execution details enabled.\n",
    "agent = initialize_agent(\n",
    "    tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, # Based on the provided prompt, you will select the optimal tool to address the issue.\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Now let's test it out!\n",
    "# The agent is run with the provided question as input.\n",
    "result = agent.run(\n",
    "    \"Em que ano a linguagem Python foi recriada e quem é o criador original? Multiplique o ano por 3.\"\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Próxima etapa:** [02_visualize.ipynb](../youtube/youtube_chat.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.17 ('langchain-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9dec8c2303d6f206f16e73aa65f91ec6cfee87fa474ea848d36adeaaca6f7956"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
