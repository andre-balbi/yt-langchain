{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import YoutubeLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from a local file\n",
    "load_dotenv(find_dotenv('../KEYS.env'))\n",
    "\n",
    "# Create an instance of the OpenAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# Define the URL of the YouTube video\n",
    "video_url = \"https://www.youtube.com/watch?v=L_Guz73e6fw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain.document_loaders.youtube.YoutubeLoader at 0x1db07c0ca60>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --------------------------------------------------------------\n",
    "# Load the YT video\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "# This loader is used to retrieve the transcript from a given YouTube video URL, \n",
    "# preparing it for further processing.\n",
    "loader = YoutubeLoader.from_youtube_url(video_url)\n",
    "\n",
    "loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --------------------------------------------------------------\n",
    "# Creating a Document from YouTube Video Transcripts\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "# Load the transcript of the video\n",
    "transcript = loader.load()\n",
    "\n",
    "# Display the first 200 characters of the page content\n",
    "transcript[0].page_content[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129690"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We are unable to utilize the complete transcript containing all \n",
    "# characters when interfacing with the API, as its length is excessively \n",
    "# extensive.\n",
    "\n",
    "# According to the API documentation, it is explicitly indicated that the \n",
    "# highest allowable count of tokens stands at 4096.\n",
    "\n",
    "len(transcript[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "959"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --------------------------------------------------------------\n",
    "# Splitting the transcript in several chunks\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "# Create a text splitter to divide the transcript into smaller chunks\n",
    "# Each chunk will have a size of 1000 characters and an overlap of 100 characters\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, \n",
    "                                               chunk_overlap=100)\n",
    "\n",
    "# Split the transcript into smaller documents using the text splitter\n",
    "docs = text_splitter.split_documents(transcript)\n",
    "\n",
    "# Number of generated documents after splitting\n",
    "len(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convertendo os fragmentos recentemente criados em vetores\n",
    "\n",
    "\n",
    "Convertendo os fragmentos recentemente criados em vetores, que são representações numéricas do próprio texto.\n",
    "\n",
    "Para isso, utilizaremos a biblioteca denominada Facebook AI Similarity Search (`FAISS`), desenvolvida para buscar documentos multimídia que apresentam semelhanças entre si (busca por similaridade). Ou seja, realizaremos uma busca por similaridade para encontrar os trechos mais parecidos com a solicitação feita pelo usuáriov via prompt.\n",
    "\n",
    "---\n",
    "\n",
    "#### Converting the Recently Created Splits into Vectors\n",
    "\n",
    "Converting the recently generated splits into vectors, which are numerical representations of the text itself.\n",
    "\n",
    "To accomplish this, we will employ the library known as Facebook AI Similarity Search (FAISS), developed to search for multimedia documents that exhibit similarities among themselves (similarity search). In other words, we will conduct a similarity search to locate the segments most akin to the user's inquiry via the prompt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![faiss](../img/faiss.JPG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain.vectorstores.faiss.FAISS at 0x1db0762fd90>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a document database using FAISS from the split documents\n",
    "db = FAISS.from_documents(docs, embeddings)\n",
    "\n",
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------\n",
    "# Combining Everything into a Function \n",
    "# --------------------------------------------------------------\n",
    "\n",
    "def create_db_from_youtube_video_url(video_url):\n",
    "    \"\"\"\n",
    "    Creates a document database from a YouTube video URL.\n",
    "\n",
    "    Args:\n",
    "        video_url (str): The URL of the YouTube video.\n",
    "\n",
    "    Returns:\n",
    "        db: A document database created from the video transcript.\n",
    "    \"\"\"\n",
    "    # Create a loader for the YouTube video transcript\n",
    "    loader = YoutubeLoader.from_youtube_url(video_url)\n",
    "\n",
    "    # Load the transcript of the video\n",
    "    transcript = loader.load()\n",
    "\n",
    "    # Create a text splitter to divide the transcript into chunks\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "\n",
    "    # Split the transcript into smaller documents\n",
    "    docs = text_splitter.split_documents(transcript)\n",
    "\n",
    "    # Create a document database using FAISS and embeddings\n",
    "    db = FAISS.from_documents(docs, embeddings)\n",
    "    \n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content=\"amazing folks I've ever met. - It takes a lot of time. Like, I spend, I mean, I think a lot of people claim to spend a third of their time hiring. I, for real, truly do. I still approve every\\nsingle hire at OpenAI. And I think there's, you know,\\nwe're working on a problem that is like very cool and that\\ngreat people wanna work on. We have great people and some\\npeople wanna be around them. But, even with that, I think\\nthere's just no shortcut for putting a ton of effort into this. - So, even when you have the\\ngood people, it's hard work. - I think so. - Microsoft announced the\\nnew multi-year multi-billion dollar reported to be 10\\nbillion investment into OpenAI. Can you describe the\\nthinking that went into this? What are the pros, what are the cons of working with a company like Microsoft? - It's not all perfect or\\neasy but, on the whole, they have been an amazing partner to us. Satya and Kevin McHale\\nare super aligned with us, super flexible, have gone\", metadata={'source': 'L_Guz73e6fw'})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --------------------------------------------------------------\n",
    "# Retrieve a response using the provided query from documents\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "query = \"What are they saying about Microsoft?\"\n",
    "\n",
    "# Search for similar documents in the database based on the query\n",
    "docs = db.similarity_search(query, \n",
    "                            k=4) # The number of similar documents to retrieve\n",
    "\n",
    "# The similar documents\n",
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"amazing folks I've ever met. - It takes a lot of time. Like, I spend, I mean, I think a lot of people claim to spend a third of their time hiring. I, for real, truly do. I still approve every\\nsingle hire at OpenAI. And I think there's, you know,\\nwe're working on a problem that is like very cool and that\\ngreat people wanna work on. We have great people and some\\npeople wanna be around them. But, even with that, I think\\nthere's just no shortcut for putting a ton of effort into this. - So, even when you have the\\ngood people, it's hard work. - I think so. - Microsoft announced the\\nnew multi-year multi-billion dollar reported to be 10\\nbillion investment into OpenAI. Can you describe the\\nthinking that went into this? What are the pros, what are the cons of working with a company like Microsoft? - It's not all perfect or\\neasy but, on the whole, they have been an amazing partner to us. Satya and Kevin McHale\\nare super aligned with us, super flexible, have gone and correct calls. And, also, he is just a super effective hands-on executive and,\\nI assume, manager too. And I think that's pretty rare. - I mean, Microsoft,\\nI'm guessing, like IBM, like a lot of companies that\\nhave been at it for a while, probably have, like, old\\nschool kind of momentum. So, you, like, inject AI\\ninto it, it's very tough. Or anything, even like the\\nculture of open source. Like, how hard is it to walk\\ninto a room and be like, the way we've been doing\\nthings are totally wrong. Like, I'm sure there's\\na lot of firing involved or a little, like, twisting\\nof arms or something. So, do you have to rule by fear, by love? Like, what can you say to the\\nleadership aspect of this? - I mean, he's just, like,\\ndone an unbelievable job but he is amazing at are super aligned with us, super flexible, have gone\\nlike way above and beyond the call of duty to do things that we have needed to get all this to work. This is, like, a big iron\\ncomplicated engineering project and they are a big and complex company and I think, like many great\\npartnerships or relationships, we've sort of just continued\\nto ramp up our investment in each other and it's been very good. - It's a for-profit\\ncompany, it's very driven, it's very large scale. Is there pressure to kind\\nof make a lot of money? - I think most other companies wouldn't, maybe now they would,\\nwouldn't at the time, have understood why we needed all the weird control provisions we have and why we need all the kind\\nof, like, AGI specialness. And I know that 'cause I\\ntalked to some other companies before we did the first\\ndeal with Microsoft and I think they are unique in terms of the companies at that\\nscale that understood why we needed the control scale that understood why we needed the control\\nprovisions we have. - And so, those control provisions help you help make sure\\nthat the capitalist imperative does not affect\\nthe development of AI. Well, let me just ask you, as an aside, about Satya Nadella, the CEO of Microsoft. He seems to have successfully\\ntransformed Microsoft into this fresh, innovative,\\ndeveloper-friendly company. - I agree. - What do you, I mean, is it really hard to do for a very large company? What have you learned from him? Why do you think he was able\\nto do this kind of thing? Yeah, what insights do you have about why this one human being is able\\nto contribute to the pivot of a large company to something very new? - I think most CEO's are either great leaders or great managers. And from what I have observed\\nwith Satya, he is both. Super visionary, really,\\nlike, gets people excited, really makes long duration\\nand correct calls. And, also, he is just a super effective hands-on executive and,\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine the page content of similar documents into a single string\n",
    "docs_page_content = \" \".join([d.page_content for d in docs])\n",
    "\n",
    "docs_page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of ChatOpenAI with settings for generating a response\n",
    "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.2)\n",
    "\n",
    "# Define a template for the system message prompt\n",
    "template = \"\"\"\n",
    "        You are a helpful assistant that can answer questions about YouTube videos \n",
    "        based on the video's transcript: {docs}\n",
    "        \n",
    "        Only use factual information from the transcript to answer the question.\n",
    "        \n",
    "        If you feel like you don't have enough information to answer the question, say \"I don't know\".\n",
    "        \n",
    "        Your answers should be verbose and detailed.\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a system message prompt template from the defined template\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
    "\n",
    "# Define a template for the human question prompt\n",
    "human_template = \"Answer the following question: {question}\"\n",
    "\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "# Create a chat prompt template from system and human message prompts\n",
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [system_message_prompt, human_message_prompt]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In the video, the speaker is discussing their partnership with Microsoft and their experience working with the company. They mention that Microsoft has been an amazing partner to them and that the CEO, Satya Nadella, and Kevin McHale have been super aligned with their goals. They describe Microsoft as flexible and willing to go above and beyond to support their needs. The speaker also praises Satya Nadella for being a visionary leader who can effectively manage and make correct decisions. They mention that Microsoft understood the unique control provisions and the importance of AGI (Artificial General Intelligence) specialness that their project requires, which other companies may not have understood. Overall, the speaker has a positive view of Microsoft and their partnership, highlighting their alignment, flexibility, and effectiveness as a large-scale company.'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an LLMChain instance for the conversation with the model\n",
    "chain = LLMChain(llm=chat, prompt=chat_prompt)\n",
    "\n",
    "# Run the chain to generate a response based on the query and documents\n",
    "response = chain.run(question=query, docs=docs_page_content)\n",
    "\n",
    "# Replace line breaks in the response\n",
    "response = response.replace(\"\\n\", \"\")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------\n",
    "# Combining Everything into a Function \n",
    "# --------------------------------------------------------------\n",
    "\n",
    "def get_response_from_query(db, query, k=4):\n",
    "    \"\"\"\n",
    "    Retrieve a response using the given query from a document database.\n",
    "\n",
    "    Args:\n",
    "        db (FAISS): A document database to search for responses.\n",
    "        query (str): The query to search for in the database.\n",
    "        k (int): The number of similar documents to retrieve.\n",
    "\n",
    "    Returns:\n",
    "        str: The response generated based on the query.\n",
    "        List[Document]: The list of similar documents from the database.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Search for similar documents in the database based on the query\n",
    "    docs = db.similarity_search(query, k=k)\n",
    "    \n",
    "    # Combine the page content of similar documents into a single string\n",
    "    docs_page_content = \" \".join([d.page_content for d in docs])\n",
    "\n",
    "    # Create an instance of ChatOpenAI with settings for generating a response\n",
    "    chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.2)\n",
    "\n",
    "    # Define a template for the system message prompt\n",
    "    template = \"\"\"\n",
    "        You are a helpful assistant that can answer questions about YouTube videos \n",
    "        based on the video's transcript: {docs}\n",
    "        \n",
    "        Only use factual information from the transcript to answer the question.\n",
    "        \n",
    "        If you feel like you don't have enough information to answer the question, say \"I don't know\".\n",
    "        \n",
    "        Your answers should be verbose and detailed.\n",
    "        \"\"\"\n",
    "\n",
    "    # Create a system message prompt template from the defined template\n",
    "    system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
    "\n",
    "    # Define a template for the human question prompt\n",
    "    human_template = \"Answer the following question: {question}\"\n",
    "    human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "    # Create a chat prompt template from system and human message prompts\n",
    "    chat_prompt = ChatPromptTemplate.from_messages(\n",
    "        [system_message_prompt, human_message_prompt]\n",
    "    )\n",
    "\n",
    "    # Create an LLMChain instance for the conversation with the model\n",
    "    chain = LLMChain(llm=chat, prompt=chat_prompt)\n",
    "\n",
    "    # Run the chain to generate a response based on the query and documents\n",
    "    response = chain.run(question=query, docs=docs_page_content)\n",
    "    \n",
    "    # Replace line breaks in the response\n",
    "    response = response.replace(\"\\n\", \"\")\n",
    "    \n",
    "    return response, docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the video transcript, the speaker mentions that Microsoft has been an amazing partner to OpenAI.\n",
      "They highlight the alignment and flexibility between the two companies, with Satya Nadella (the CEO\n",
      "of Microsoft) and Kevin McHale being mentioned as being super aligned with OpenAI. The speaker also\n",
      "praises Satya Nadella for being a super effective hands-on executive and manager. They mention that\n",
      "Microsoft has gone above and beyond to support OpenAI and have been willing to make the necessary\n",
      "adjustments and investments to make their partnership successful. The speaker also mentions that\n",
      "Microsoft is a large-scale, for-profit company and acknowledges that there may be pressure to make a\n",
      "lot of money. However, they also mention that Microsoft understood the unique control provisions\n",
      "that OpenAI needed for the development of AGI (Artificial General Intelligence), which sets them\n",
      "apart from other companies at that scale. Overall, the speaker has a positive view of Microsoft and\n",
      "their partnership with OpenAI.\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------\n",
    "# Example usage\n",
    "# --------------------------------------------------------------\n",
    "# Define the URL of the YouTube video\n",
    "video_url = \"https://www.youtube.com/watch?v=L_Guz73e6fw\"\n",
    "\n",
    "# Create a document database from the YouTube video transcript\n",
    "db = create_db_from_youtube_video_url(video_url)\n",
    "\n",
    "# Define a query to ask about Microsoft\n",
    "query = \"What are they saying about Microsoft?\"\n",
    "\n",
    "# Retrieve a response and similar documents from the database based on the query\n",
    "response, docs = get_response_from_query(db, query)\n",
    "\n",
    "# Print the response, formatting it to fit within 100 characters per line\n",
    "print(textwrap.fill(response, width=100))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.17 ('langchain-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9dec8c2303d6f206f16e73aa65f91ec6cfee87fa474ea848d36adeaaca6f7956"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
